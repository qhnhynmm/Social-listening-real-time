{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1718260827640,"sparkVersion":"3.5.1","uid":"Tokenizer_6b2d32687e58","paramMap":{"outputCol":"words","inputCol":"Cleaned Content"},"defaultParamMap":{"outputCol":"Tokenizer_6b2d32687e58__output"}}
